close all;
clear;
clc;

% load .\data\original_data\lymphoma.mat
 load .\data\original_data\nci64.mat
data=Sample';
[m,n]=size(data);
classNum=numel(unique(data(:,end)));    %class number
iterators=20;
crossK=5;
sumAdaBoostEveryIter=0;
sumSVMEveryIter=0;
sumRandomForestIter=0;
sumKNNIter=0;
for j=1:iterators
    fprintf('*********The %d th round iterator start***********\n',j);
    indices = crossvalind('Kfold', m, crossK);%??????????3??    
    for i = 1:crossK %??3???????i????????????????????
        test1 = (indices == i);
        train = ~test1;
        trainData = data(train, :);
        testData = data(test1, :);
        trainX=trainData(:,1:end-1);
        trainY=trainData(:,end);
        testX=testData(:,1:end-1);
        testY=testData(:,end);
        if classNum==2
             ada = fitensemble(trainX,trainY,'AdaBoostM1',200,'Discriminant');
        else
            ada = fitensemble(trainX,trainY,'AdaBoostM2',200,'tree');
        end                 
        result = predict(ada,testX);
        AccuracyRate = sum(result == testY) / length(testY);        
        sumAdaBoostEveryIter=sumAdaBoostEveryIter+AccuracyRate;
        fprintf('*********Accuracy: %d ***********\n',AccuracyRate);
    end
    fprintf('*********The %d th round iterator end***********\n',j);
end
fprintf('AdaBoost Average Accuracy:%d\n',sumAdaBoostEveryIter/(iterators*crossK));





% result = DecisionTree(trainX,trainY,testX,testY);   %Â¾Ã¶Â²ÃŸÃŠÃ·
% result = NeuroNetwork(trainX,trainY,testX,testY);   %Ã‰Ã±Â¾Â­Ã?Ã¸Ã‚Ã§
% result = SVMDecision(trainX,trainY,testX,testY);    %SVM
% result = BayesNaive(trainX,trainY,testX,testY);     %Naive Bayes
% result = AdaBoost(trainX,trainY,testX,testY);       %AdaBoost
% result = RandomForest(trainX,trainY,testX,testY);   %random forest
